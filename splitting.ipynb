{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 5, 6, 9, 10] 1\n"
     ]
    }
   ],
   "source": [
    "# my_list = [2,4,5,6 , 9,10, 4,5]\n",
    "# valid = 0.2 * len(my_list)\n",
    "# train = 0.7 * len(my_list)\n",
    "# eval = 0.1 * len(my_list)\n",
    "# print(my_list[0:int(train) + 1], int(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_list = [2, 4, 5, 6, 9, 10, 4, 5]\n",
    "\n",
    "# # Compute sizes\n",
    "# train_size = int(0.7 * len(my_list))   # 70% for training\n",
    "# valid_size = int(0.2 * len(my_list))   # 20% for validation\n",
    "# eval_size = len(my_list) - (train_size + valid_size)  # Remaining for testing\n",
    "\n",
    "# # Split dataset\n",
    "# train_set = my_list[:train_size]  \n",
    "# valid_set = my_list[train_size:train_size + valid_size]  \n",
    "# test_set = my_list[train_size + valid_size:]  \n",
    "\n",
    "# # Print results\n",
    "# print(f\"Train set: {train_set} ({len(train_set)})\")\n",
    "# print(f\"Validation set: {valid_set} ({len(valid_set)})\")\n",
    "# print(f\"Test set: {test_set} ({len(test_set)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset successfully split into train, val, and eval sets.\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# # Define dataset paths\n",
    "# dataset = './asl_data_res_aug'\n",
    "# output_dir = './dataset'\n",
    "\n",
    "# # Define split directories\n",
    "# train_dir = os.path.join(output_dir, 'train')\n",
    "# valid_dir = os.path.join(output_dir, 'val')\n",
    "# test_dir = os.path.join(output_dir, 'eval')\n",
    "\n",
    "# # Ensure directories exist\n",
    "# for folder in [train_dir, valid_dir, test_dir]:\n",
    "#     os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# # Walk through dataset and split\n",
    "# for dirpath, dirnames, filenames in os.walk(dataset):\n",
    "#     if not filenames:  # Skip empty directories\n",
    "#         continue\n",
    "#     # class_label = os.path.basename(dirpath)  # Extract class name\n",
    "#     # class_output_folder = os.path.join(output_dir, class_label)\n",
    "\n",
    "#     # Compute sizes\n",
    "#     train_size = int(0.7 * len(filenames))  # 70% for training\n",
    "#     valid_size = int(0.2 * len(filenames))  # 20% for validation\n",
    "#     test_size = len(filenames) - (train_size + valid_size)  # Remaining for testing\n",
    "\n",
    "#     # Shuffle dataset to randomize splits\n",
    "#     filenames.sort()  # Optional: You can also use random.shuffle(filenames)\n",
    "\n",
    "#     # Split dataset\n",
    "#     train_set = filenames[:train_size]\n",
    "#     valid_set = filenames[train_size:train_size + valid_size]\n",
    "#     test_set = filenames[train_size + valid_size:]\n",
    "\n",
    "#     # Move files to corresponding directories\n",
    "#     for filename in train_set:\n",
    "#         shutil.move(os.path.join(dirpath, filename), os.path.join(train_dir, filename))\n",
    "\n",
    "#     for filename in valid_set:\n",
    "#         shutil.move(os.path.join(dirpath, filename), os.path.join(valid_dir, filename))\n",
    "\n",
    "#     for filename in test_set:\n",
    "#         shutil.move(os.path.join(dirpath, filename), os.path.join(test_dir, filename))\n",
    "\n",
    "# print(\"Dataset successfully split into train, val, and eval sets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset successfully split into train, val, and eval sets while retaining class structure!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Define dataset paths\n",
    "import os\n",
    "os.makedirs('./dataset')\n",
    "dataset = './asl_data_res_aug'  # Source dataset\n",
    "output_dir = './dataset'  # Output base directory\n",
    "\n",
    "# Define split directories\n",
    "train_dir = os.path.join(output_dir, 'train')\n",
    "valid_dir = os.path.join(output_dir, 'val')\n",
    "test_dir = os.path.join(output_dir, 'test')\n",
    "\n",
    "# Ensure base directories exist\n",
    "for folder in [train_dir, valid_dir, test_dir]:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# Walk through dataset and split while preserving class structure\n",
    "for dirpath, dirnames, filenames in os.walk(dataset):\n",
    "    if not filenames:  # Skip empty directories\n",
    "        continue\n",
    "\n",
    "    class_label = os.path.basename(dirpath)  # Extract class name\n",
    "    class_train_dir = os.path.join(train_dir, class_label)\n",
    "    class_valid_dir = os.path.join(valid_dir, class_label)\n",
    "    class_test_dir = os.path.join(test_dir, class_label)\n",
    "\n",
    "    # Create class subdirectories if they don't exist\n",
    "    for folder in [class_train_dir, class_valid_dir, class_test_dir]:\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # Shuffle dataset to randomize splits\n",
    "    random.shuffle(filenames)  \n",
    "\n",
    "    # Compute sizes\n",
    "    train_size = int(0.7 * len(filenames))  # 70% for training\n",
    "    valid_size = int(0.2 * len(filenames))  # 20% for validation\n",
    "    test_size = len(filenames) - (train_size + valid_size)  # Remaining for testing\n",
    "\n",
    "    # Split dataset\n",
    "    train_set = filenames[:train_size]\n",
    "    valid_set = filenames[train_size:train_size + valid_size]\n",
    "    test_set = filenames[train_size + valid_size:]\n",
    "\n",
    "    # Copy files to corresponding directories while keeping class structure\n",
    "    for filename in train_set:\n",
    "        shutil.copy(os.path.join(dirpath, filename), os.path.join(class_train_dir, filename))\n",
    "\n",
    "    for filename in valid_set:\n",
    "        shutil.copy(os.path.join(dirpath, filename), os.path.join(class_valid_dir, filename))\n",
    "\n",
    "    for filename in test_set:\n",
    "        shutil.copy(os.path.join(dirpath, filename), os.path.join(class_test_dir, filename))\n",
    "\n",
    "print(\"Dataset successfully split into train, val, and eval sets while retaining class structure!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".asl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
